{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import os\n",
    "import re\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "Read in your tabular data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to datafile\n",
    "df = pd.read_excel('data/agenda_export_spspa_202402 MJ.xls', sheet_name=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data\n",
    "\n",
    "Write whatever code is necessary for your own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for poster sessions\n",
    "df_posters = df.loc[df['Tracks'].str.contains('Poster', na=False) & \n",
    "                    ~df['*Session Title'].str.contains('Poster Session', na=False) &\n",
    "                    df['Authors'].notna()].reset_index(drop=True)\n",
    "\n",
    "# Remove rows with no description\n",
    "df_posters = df_posters.dropna(subset=['Description'])\n",
    "\n",
    "# Edit titles to remove the initial \"[number]\" portion\n",
    "df_posters['*Session Title'] = [re.sub(r\"^\\[\\d+\\]\", \"\", title).strip() for title in df_posters['*Session Title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Embeddings\n",
    "\n",
    "You will need an API key from OpenAI for this.\n",
    "\n",
    "Here is a [quickstart guide](https://platform.openai.com/docs/quickstart?context=python).\n",
    "\n",
    "Also you can choose a different embedding model - we are using `text-embedding-3-small` which is current as of Februrary 2024.\n",
    "\n",
    "More info on the model [here](https://openai.com/blog/new-embedding-models-and-api-updates).\n",
    "\n",
    "OpenAI also has an [Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the API key from an environment variable\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to get embeddings\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "# Combine Title and Description\n",
    "df_posters['Description'] = df_posters['Description'].astype(str)\n",
    "df_posters['combined'] = df_posters['*Session Title'] + ' ' + df_posters['Description']\n",
    "\n",
    "# Get embeddings (this can take some time)\n",
    "df_posters['embedding_3small'] = df_posters.combined.apply(lambda x: get_embedding(x, model='text-embedding-3-small'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save embeddings matrix\n",
    "for index, row in df_posters.iterrows():\n",
    "    if index ==0:\n",
    "        embeddings_array = np.array(df_posters['embedding_3small'][index])\n",
    "    if index >0:\n",
    "        embeddings_array = np.vstack((embeddings_array, np.array(df_posters['embedding_3small'][index])))\n",
    "\n",
    "np.savez('output/embeddings_array.npz', embeddings_array = embeddings_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "You can use whichever methods you prefer for this.\n",
    "\n",
    "We also just used the default settings but cleaner seperation could well be possible by tweaking the hyperparameters.\n",
    "\n",
    "This is more of an aesthetic choice, as the actual similarity scores that are used for finding matching papers are using a different method (cosine similarity) on the full embedding vector of 1536 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 2 dimensional data and save these values to df\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d_pca = pca.fit_transform(embeddings_array)\n",
    "\n",
    "# Add to df\n",
    "df_posters['pca1'] = embeddings_2d_pca[:,0]\n",
    "df_posters['pca2'] = embeddings_2d_pca[:,1]\n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings_2d_tsne = tsne.fit_transform(embeddings_array)\n",
    "\n",
    "# Add to df\n",
    "df_posters['tSNE1'] = embeddings_2d_tsne[:,0]\n",
    "df_posters['tSNE2'] = embeddings_2d_tsne[:,1]\n",
    "\n",
    "# Save dataframe\n",
    "df_posters.to_csv('output/spsp_wEmbeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
